{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"http://i.imgur.com/sSaOozN.png\" width=\"500\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Course: Computational Thinking for Governance Analytics\n",
    "\n",
    "### Prof. José Manuel Magallanes, PhD \n",
    "\n",
    "_____\n",
    "\n",
    "# Session 3:  Data Exploration for Governance Analytics in Python \n",
    "\n",
    "## Part A: Univariate case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EDA is the most important stage to confirm or modify your research. It you are familiar with theories that suggests certain explanations to social outcomes, but you have never looked through the data associated with the phenomenon(a) of interest, you may get interesting surprises. \n",
    "\n",
    "Let's work at the individual variable level, keeping in mind that your data has many variables (columns) which you do not to explore if they are not currently considered in your research questions; it is also the case that you may not need all the cases (rows). \n",
    "\n",
    "\n",
    "EDA is done to closely know the behavior of the data; however, the possibility to detect that behavior depends on the nature of the data at hand. Also, keep in mind that while exploring your data, some data cleaning and formatting may need to be done, as well as some sub setting and slicing of your original data set. Real data sets do not come ready to be analyzed by the powerful functions that Python has.\n",
    "\n",
    "Let's visit this [website](http://nces.ed.gov/datatools/) and get all the data available for public schools in Washington (when prompted I named the file 'wapubs.xlsx'). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd # may also need xlrd for Excel\n",
    "dataFile='https://github.com/EvansDataScience/data/raw/master/wapubs.xlsx'\n",
    "# we will jump 11 rows\n",
    "schoolPub=pd.read_excel(dataFile,0,skiprows=11) # pandas calls directly (not like R)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These data have these columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "schoolPub.dtypes # pandas was smart to recognize the type of data in most columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='head'></a>\n",
    "If you are not familiar with the variable names, you can find this [glossary](http://nces.ed.gov/ccd/commonfiles/glossary.asp) useful. \n",
    "\n",
    "Unless you are familiar with a particular file, you will find different challenges to explore the data. A good data exploration depends on properly identifying the nature of each variable:\n",
    "\n",
    "* Categorical\n",
    "    * [Dichotomous](#Dichotomous)\n",
    "    * Polytomous\n",
    "        * [Non-Ordinal](#Nordinal)\n",
    "        * [Ordinal](#Ordinal)\n",
    "* Numerical\n",
    "    * [Counts](#Counts)\n",
    "    * [Measurements](#Measurements) (ratio or interval scale)\n",
    "    \n",
    "I will also pay attention to the concept of [outliers](#outliers), at the end of this part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "____\n",
    "\n",
    "<a id='Dichotomous'></a> \n",
    "## <span style=\"color:blue\"> Exploring Dichotomous data</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's turn our attention to  schools whose percentage of low-income students is at least 40 percent. This is the distribution of its values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "schoolPub['Title 1 School Wide*'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you prefer to see relative frequencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "schoolPub['Title 1 School Wide*'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From these results, you have no doubts that there are much more schools of this kind than of the other. \n",
    "\n",
    "Sometimes, it is useful (not in this case) to run a $\\chi^2$ test to see if the differences are significant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import chisquare\n",
    "\n",
    "distribution=schoolPub['Title 1 School Wide*'].value_counts()\n",
    "chisquare(distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result above is telling you that the probability that this distribution behaves like a uniform distribution is very low; so a safe decision is to assume that the differences in the frequencies are significant.\n",
    "\n",
    "The above result included the _not applicable_ symbol. We can get rid of it and re test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the symbol † as missing value:\n",
    "import numpy as np  #numpy manages the nan for pandas\n",
    "symbolsForNA=['†']\n",
    "schoolPub.replace(symbolsForNA,np.nan,inplace=True) # in the whole data frame!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should get a clean frequency table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "schoolPub['Title 1 School Wide*'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# re testing:\n",
    "distribution=schoolPub['Title 1 School Wide*'].value_counts()\n",
    "chisquare(distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The equal distribution of frequencies is rejected again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Central measurement and dispersion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **mode** is the measure of centrality for dichotomous values. You can detect it just by watching the frequency, but let's see it using _Pandas_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "schoolPub['Title 1 School Wide*'].mode()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Go to begining](#head)\n",
    "____\n",
    "\n",
    "<a id='Nordinal'></a> \n",
    "## <span style=\"color:blue\"> EDA for non-ordinal polytomous variables</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's pay attention to the school location:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "schoolPub['Locale*'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a weird category \"N\". Before making any decision, let's try to find out what is going on in that row:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "schoolPub[schoolPub['Locale*']=='N']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You see many _not applicable_ symbols in the school categories. As it is not clear why this school is here, we can just recode that cell as missing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "schoolPub.loc[1193,'Locale*']=np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check its data type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "schoolPub['Locale*'].dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We detect inmediately that we have an _object_ instead of a _category_, let's solve that too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "schoolPub['Locale*']=schoolPub['Locale*'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function _describe_ can be applied to categories, but you get not much:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "schoolPub['Locale*'].describe()  # 'top' is the mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Central Value\n",
    "\n",
    "The central value of polytomous variables (and dichotomous) is the mode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the well known mode:\n",
    "schoolPub['Locale*'].mode()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We knew that from the previous frequency table and from _describe_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dispersion\n",
    "\n",
    "The measure of dispersion is used to inform if the central value is representative. One way to quantify this concept in polytomous variables is via the Gini Index here, which is present in the versatile package _pysal_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pysal.inequality.gini import Gini\n",
    "Gini(schoolPub['Locale*'].value_counts()).g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The closer the index gets to zero would mean the mode loses salience, the closer to 1, the more salient it is. The Gini is not the best way to measure inequality, but worth using it for comparative purposes<sup><a href=\"#fn1\" id=\"ref1\">1</a></sup>.\n",
    "\n",
    "The above result confirms that there is not one value that has the greater share. But we do not have an equal distribution, do we?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chisquare(schoolPub['Locale*'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the results above, the most probable is that this variable does not follow a uniform distribution.\n",
    "\n",
    "Let's see a simple plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this is needed!\n",
    "%matplotlib inline  \n",
    "\n",
    "schoolPub['Locale*'].value_counts(sort=False).plot.bar(color='r')\n",
    "\n",
    "# we are plotting the frequency table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about highlighting the mode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categories=schoolPub['Locale*'].cat.categories # all the categories\n",
    "modes=list(schoolPub['Locale*'].mode()) # list of 'modes' (from the categories)\n",
    "\n",
    "newPalette = ['r' if (x in modes) else 'y' for x in categories] #list of colors\n",
    "\n",
    "# changing palette:\n",
    "schoolPub['Locale*'].value_counts(sort=False).plot.bar(color=newPalette)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dispersion is clear so far, this plot could help highlighting the subpopulations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt # needed for more customization\n",
    "\n",
    "newerPalette=['grey']*3 + ['orange']*3 + ['turquoise']*3 + ['lightblue']*3\n",
    "schoolPub['Locale*'].value_counts(sort=False).plot.bar(color=newerPalette, title=\"The Title\")\n",
    "plt.ylabel('COUNT')\n",
    "plt.xlabel('CATEGORIES')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Go to begining](#head)\n",
    "____\n",
    "\n",
    "<a id='Ordinal'></a>\n",
    "## <span style=\"color:blue\"> EDA for ordinal categorical variables</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's consider for this section the variable that tells us the highest grade offered in a school. A simple exploration gives:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# any weird symbols in the categories:\n",
    "schoolPub['High Grade*'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# if this is not categorical, we will change soon:\n",
    "schoolPub['High Grade*'].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The _'O'_ type is not a category. As there is no need to replace weird symbols, we'll just go ahead and set it as ordinal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we set it up as both category and ordinal:\n",
    "from pandas.api.types import CategoricalDtype\n",
    "schoolPub['High Grade*']=schoolPub['High Grade*'].astype(CategoricalDtype(ordered=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's find out the ordered assigned:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "schoolPub['High Grade*'].cat.categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The _index_ showed the current order. That should be changed, because _PK_ and _KG_ are first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "levels=list(schoolPub['High Grade*'].cat.categories) # turn index into a list\n",
    "# last two elements: levels[-2:]\n",
    "# reverse those last two: reversed(levels[-2:])\n",
    "# turn it into a list: list(reversed(levels[-2:]))\n",
    "# append the rest: + levels[0:-2]\n",
    "list(reversed(levels[-2:]))+ levels[0:-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With that information, I can re set the categories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newCategories=list(reversed(levels[-2:]))+ levels[0:-2]\n",
    "schoolPub['High Grade*']=schoolPub['High Grade*'].cat.reorder_categories(newCategories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# confirming:\n",
    "schoolPub['High Grade*'].value_counts(sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The describe function does not offer much:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "schoolPub['High Grade*'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Central Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# as always the mode:\n",
    "schoolPub['High Grade*'].mode()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An important central value in ordered categories is the **median**. We need to transform the counts to percent, acummulate the sum of percents, and find the value where the cummulative sum reaches 50%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.cumsum(schoolPub['High Grade*'].value_counts(sort=False,normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After identifying the median visually, I can use this code to find the median:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "relFrequencies=schoolPub['High Grade*'].value_counts(sort=False,normalize=True) \n",
    "cumulativeTable=np.cumsum(relFrequencies)\n",
    "pos =0\n",
    "for percent in cumulativeTable:\n",
    "    if percent < 0.5: \n",
    "        pos +=1 \n",
    "    else:\n",
    "        break\n",
    "cumulativeTable.index[pos] # 'index' tells you position not value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It means that 50% of the schools offer at most 8th grade."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dispersion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What value of Gini do you expect?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Gini(schoolPub['High Grade*'].value_counts()).g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gini tells that there is some concentration. The plot should help us get a better idea:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "schoolPub['High Grade*'].value_counts(sort=False).plot.bar(color='r', title=\"The Title\")\n",
    "plt.ylabel('COUNT')\n",
    "plt.xlabel('CATEGORIES')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There was one mode, but a few other competing categories with high counts, these 4 categories concentrated much more than the 11 remaining combined."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skewness\n",
    "\n",
    "We can not compute a proper measure of symmetry as there is no distance among the categories, but we know there is lack of symmetry because the two central values are different. As the mode is to the right of the median, we could expect a longer left tail. Let's prepare the plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# no missing values: schoolPub['High Grade*'].dropna()\n",
    "# valid values into numeric: schoolPub['High Grade*'].dropna().cat.codes\n",
    "\n",
    "schoolPub['High Grade*'].dropna().cat.codes.plot.box(color='r', title=\"The Title\",vert=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shape is OK, but the labels are wrong, because we turned them into numbers, this is how we change it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labelsCat=list(schoolPub['High Grade*'].cat.categories) # name of categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ax=schoolPub['High Grade*'].dropna().cat.codes.plot.box(color='r', title=\"The Title\",vert=False)\n",
    "ax.set(xticks=range(0, 15)) # values in axis\n",
    "ax.set_xticklabels(labelsCat)  # labels for the axis\n",
    "plt.show() # if you omit this you get the plot and also extra info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python also has the library _seaborn_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "ax = sns.boxplot(x=schoolPub['High Grade*'].dropna().cat.codes)\n",
    "\n",
    "ax.set(xticks=range(0, 15)) # values in axis\n",
    "ax.set_xticklabels(labelsCat)  # labels for the axis\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Go to begining](#head)\n",
    "____\n",
    "\n",
    "<a id='Counts'></a> \n",
    "\n",
    "## <span style=\"color:blue\"> EDA for Counts</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cross sectional counts**\n",
    "\n",
    "I have a file about Supplemental Nutrition Assistance Program (SNAP) beneficiaries data by counties, in a cross sectional fashion, let me use it here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dataFile=\"https://github.com/EvansDataScience/data/raw/master/cntysnap.xls\"\n",
    "snapBen=pd.read_excel(dataFile,0,skiprows=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "snapBen.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "snapBen.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a county has a FIPS code equal to 0, then that row is informing about the State. Keeping the counties only:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "snapBenCounties=snapBen[snapBen['County FIPS code']!=0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Centrality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, describe() does give more information, we can get mean and median, and the quartiles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "snapBenCounties.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skewness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In numeric data it is easier to detect skewness, we want to know if the bulk of the data is biasing towards a particular direction. In evene easier terms, we want to know if the difference between mean and median is positive or negative, if it is positive, the bulk of the data is moving towards the left (or the tail is longer to the rigth)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "snapBenCounties.loc[:,'July 2013':'July 1989'].mean()-snapBenCounties.loc[:,'July 2013':'July 1989'].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a particular skewness measure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "snapBenCounties.loc[:,'July 2013':'July 1989'].skew()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All are positive, which means that every year the right tail is salient: there are some counties, not the majority, that have much more beneficiaries than the rest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kurtosis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To complete the picture of what is going on with this variable, we should know if the values around the mode are salient or not. The more salient they are the distribution is called leptokurtic; the less salient, platycurtic (or mesokurtic if it behaves as a normal distribution). Let’s do it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "snapBenCounties.loc[:,'July 2013':'July 1989'].kurt()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems every column is distributed similarly every year. Let's prepare data for plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#current order of columns as  alist:\n",
    "currentOrder=snapBenCounties.columns.tolist()\n",
    "#re arranging order:\n",
    "newOrder=currentOrder[0:3]+list(reversed(currentOrder[3::]))\n",
    "# years ascending\n",
    "snapBenCounties=snapBenCounties[newOrder]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=1)\n",
    "snapBenCounties.loc[:,'July 1989':'July 2013'].skew().plot(ax=axes[0],color='r',title=\"sk\")\n",
    "snapBenCounties.loc[:,'July 1989':'July 2013'].kurt().plot(ax=axes[1],title=\"kt\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "snapBenCounties.loc[:,'July 1989':'July 2013'].skew().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both are very similar, and extremely large by the second half of the 1990s.\n",
    "\n",
    "It would a good idea to plot the original data (not the coefficients) per year:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "snapBenCounties.loc[:,'July 1989':'July 2013'].hist(color='k', alpha=0.5, bins=50,figsize=(20,20),xrot=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about a box plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "DATA=snapBenCounties.loc[:,'July 1989':'July 2013'].boxplot(rot =90, sym='.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about highlighting WA state in a particular year:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data\n",
    "DATA=snapBenCounties.loc[:,list(np.delete(snapBenCounties.columns,(1,2)))] # without column 2 and 3\n",
    "\n",
    "# palette:\n",
    "pal = {state: \"r\" if state == 53 else \"y\" for state in DATA['State FIPS code'].unique()}\n",
    "# plotting:\n",
    "plt.figure(figsize=(20,15))\n",
    "sns.boxplot(x='State FIPS code', y='July 2013', data=DATA, palette=pal,linewidth=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Go to begining](#head)\n",
    "____\n",
    "\n",
    "<a id='Measurements'></a> \n",
    "\n",
    "## <span style=\"color:blue\"> EDA for measurements</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let use a data set on 2015 Poverty and Median Household Income Estimates per county in the USA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dataFile=\"https://github.com/EvansDataScience/data/raw/master/est15ALL.xls\"\n",
    "columnsWanted=list(range(4))+[22]\n",
    "income=pd.read_excel(dataFile,0,skiprows=3,usecols=columnsWanted) # COLUMNS TO RECOVER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "income.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The _County FIPS Code_ is useful to keep just the counties:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#subsetting\n",
    "incomeCounties=income[income['County FIPS Code']!=0]\n",
    "\n",
    "#seeing:\n",
    "incomeCounties.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "incomeCounties.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Income is an object, let's see if we can change each valu to numeric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in incomeCounties['Median Household Income']:\n",
    "    try:\n",
    "        float(i)\n",
    "    except:\n",
    "        print (i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a '.' in the cells representing missing values. I could reopen the file, telling python that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "income=pd.read_excel(dataFile,0,skiprows=3,usecols=columnsWanted,na_values='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "incomeCounties=income[income['County FIPS Code']!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "incomeCounties.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Centrality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get centrality measures using _describe_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "incomeCounties['Median Household Income'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dispersion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get the standard deviation and the coefficient of variation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "incomeCounties['Median Household Income'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "incomeCounties['Median Household Income'].std()/incomeCounties['Median Household Income'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skewness\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "incomeCounties['Median Household Income'].skew()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kurtosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "incomeCounties['Median Household Income'].kurt()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now pay more attention to the histogram, and how to show some info on it, like its normal curve:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "sns.distplot(incomeCounties['Median Household Income'].dropna(),kde=False, fit=norm) # w/o missing values\n",
    "plt.legend(('data fit to normal','data as it is'))\n",
    "plt.title('How is the income distributed in the USA?')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The histogram with central measures…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#statistics:\n",
    "mnVar=incomeCounties['Median Household Income'].mean()\n",
    "mdVar=incomeCounties['Median Household Income'].median()\n",
    "\n",
    "sns.distplot(incomeCounties['Median Household Income'].dropna(),kde=False,fit=norm)\n",
    "plt.title('The closer the mean to the median, the more inequality?')\n",
    "plt.axvline(mnVar, color='b', linestyle='dashed', linewidth=2,label='mean')\n",
    "plt.axvline(mdVar, color='r', linestyle='dashed', linewidth=2,label='median')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's focus in a couple of States:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "incWaCounties=incomeCounties[incomeCounties['Postal Code']=='WA']\n",
    "incCaCounties=incomeCounties[incomeCounties['Postal Code']=='CA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plotting CA\n",
    "plt.hist(incCaCounties['Median Household Income'], color='orange',label='CA')\n",
    "plt.axvline(incCaCounties['Median Household Income'].mean(), color='darkorange', linestyle='dashed', linewidth=2,label='mean CA')\n",
    "\n",
    "# Plotting WA\n",
    "plt.hist(incWaCounties['Median Household Income'], color='lightgreen',alpha=0.9, label='WA')\n",
    "plt.axvline(incWaCounties['Median Household Income'].mean(), color='darkgreen', linestyle='dashed', linewidth=2,label='mean WA')\n",
    "\n",
    "# for both plots:\n",
    "plt.legend(loc='upper right',ncol=2)\n",
    "plt.title('Is CA income better than WA?')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "<a id='outliers'></a>\n",
    "\n",
    "## Outliers in data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Real data comes most of the time with outliers. These are not bad things, it is just the identification that a value seems to be 'different' than the rest. So, the problem to find outliers is also the problem to define what makes a majority of 'similar' values. This is crucial point in governance analytics, as the 'common good' becomes a very subjective concept in computational terms. \n",
    "\n",
    "For this topic, we will use the data if SNAP previously explored (particularly the subset at county level)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's pay attention to the  year 2013 and get some descriptives first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "snapBenCounties['July 2013'].describe() # snapBenCounties[['July 2013']].info() technical info..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's pay attention to the quartile (25th and 75th percentile). These are elements in boxplots, and their difference, the intequartile range (IQR) is used to identify outliers numerically and visually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot,dataBP=snapBenCounties['July 2013'].plot.box(vert=False,return_type='both')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The command above not only plotted the boxplot, but when I added the parameter *return_type* I saved several  _values_ used by python to build the boxplot. For instance, the box limits are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[value.get_xdata() for value in dataBP[\"boxes\"]] # limits of the boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we confirmed the boxplot boxes are limited by the 25th and 75th percentile (they are the same as the one we got using _describe()_, right?).\n",
    "You can get more information from the variable _dataBP_; besides information about the 'boxes', you also have 'whiskers', 'medians', 'caps', and 'fliers'. Let me use 'caps':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# box plot lines for min and max values, NOT considered outliers\n",
    "[value.get_xdata() for value in dataBP[\"caps\"]] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you see, the lowest cap of the boxplot is the same as the one found using _describe()_, but NOT the maximum. The command _describe()_ informs that the max value of the variable is..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "snapBenCounties['July 2013'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... while the highest values cap is 24030; then all the values greater than this one will be considered outliers. \n",
    "\n",
    "You know how this happened, right?..if not, let me refresh the process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The 'caps' are computed usng the interquartile range (IQR).\n",
    "# The IQR is the distance between the first and third quartile;\n",
    "# or, in other terms, the distance between the 75th and 25th percentiles:\n",
    "\n",
    "# 1. Computing 75th and 25th percentiles:\n",
    "q25,q75=snapBenCounties['July 2013'].quantile([0.25,0.75])\n",
    "\n",
    "# 2. Computing the distance between them or IQR:\n",
    "IQR=q75-q25\n",
    "\n",
    "# which is:\n",
    "IQR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, once the IQR is computed, it is multiplied by 1.5; the result is added / subtracted to the 75th/25th percentile:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "capHigh = q75 + IQR*1.5\n",
    "capHigh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "capLow=q25 - IQR*1.5\n",
    "capLow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any value above capHigh or below capLow will be considered a possible outlier.\n",
    "\n",
    "According to this process, we do not have outliers in the lowest values, but several in the upper ones. If it is so, the amount of outlying values is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len([flier.get_xdata() for flier in dataBP[\"fliers\"]][0])\n",
    "# you can see them using:\n",
    "# [flier.get_xdata() for flier in dataBP[\"fliers\"]][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is this approach to find outliers? \n",
    "\n",
    "The idea is to see what values are far from the 'mass' (between the 25th and 75th percentiles) but for that, there is an assumption that the mass is around an 'average' value (the median), and that the outliers are symmetrically distant from that average. In this case that distance is the IQR multiplied by some constant. You can increase the constant to find extreme outliers.\n",
    "\n",
    "Instead of using the median, we could try the mean; but then we need to adapt the approach so that instead of using IQR, we use the standard deviation instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "StdDev=snapBenCounties['July 2013'].std()\n",
    "Mean=snapBenCounties['July 2013'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Then\n",
    "lowCapT=Mean-2*StdDev\n",
    "lowCapT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# and \n",
    "upCapT=Mean+2*StdDev\n",
    "upCapT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This interval will give us less outliers, and again, all of them are in the right tail. The amount of outliers here will be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(snapBenCounties['July 2013'][snapBenCounties['July 2013']>upCapT])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could represent this new 'cap' in the boxplot, but since the boxplot requires percentiles for the whiskers we need to find what peecentile the value _upCapT_ represents; we can do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "new_capHigh=stats.percentileofscore(snapBenCounties['July 2013'], upCapT)\n",
    "# see:\n",
    "new_capHigh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a clearer idea of what the percentile is, so we give that to the plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "limits=[100-new_capHigh,new_capHigh]\n",
    "arguments={'kind':'box', \"vert\":False,'return_type':'both','whis':limits,'sym':'*'}\n",
    "plot,dataBP=snapBenCounties['July 2013'].plot(**arguments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are we satisfied? This is the original data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# notice the amount of bins:\n",
    "snapBenCounties['July 2013'].plot(kind='hist',bins=100,figsize=(10, 8)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And this is the data without the boxplot outliers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "snapBenCounties['July 2013'][snapBenCounties['July 2013']<q75+1.5*IQR].plot(kind='hist', bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a very asymmetric distribution; so we should be careful. If this were a real long-tail distribution, using our previous techniques may fail detecting outliers, specially in the lower tail. Let me see how it looks when I transform the values into logarithmic ones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.log(snapBenCounties['July 2013']).plot(kind='hist')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is the log version far from a normal distribution? Let's compare with the normal distribution visually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from scipy.stats import norm\n",
    "\n",
    "# need data without missing values\n",
    "sns.distplot(np.log(snapBenCounties['July 2013'].dropna()), fit=norm, kde=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the \"new\" outliers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arguments={'kind':'box', 'vert':False,'return_type':'both','sym':'*'}\n",
    "plot,dataBPlog=np.log(snapBenCounties['July 2013']).plot(**arguments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the amount of outliers detected, this time in both sides:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len([value.get_xdata() for value in dataBPlog[\"fliers\"]][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let me recover the _caps_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "caps=[value.get_xdata()[0] for value in dataBPlog[\"caps\"]] #notice trick: \"[0]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving each cap:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "low=caps[0]\n",
    "up=caps[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use this to create a new column _flagging_ a cell when a county is an outlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a function to recode\n",
    "myRecode=lambda x:1 if x<low else 2 if x>up  else np.nan if pd.isnull(x) else 0  #control missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#apply function and create new column\n",
    "snapBenCounties['out2013']=np.log(snapBenCounties['July 2013']).map(myRecode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#verify snapBenCounties['out2013']count: do we hve 115 flags? YES\n",
    "snapBenCounties['out2013'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "snapBenCounties[['Name','out2013']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counties names can repeat, but not States. We have no states in the columns, so we create it from the column _Name_. Let em show you the steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# using split,a function for strings:\n",
    "'Autauga County, AL'.split(', ') # notice the space after the comma\n",
    "# you get a list:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the small example above, we can build a simple function that reads a string and splits it, keeping the second value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "splitAndGetSecondElement=lambda valueAsString: valueAsString.split(', ')[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then apply that function to this one column of names? Let me see if this works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "snapBenCounties.Name.map(splitAndGetSecondElement) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It works as expected, then I can create a new column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save result:\n",
    "states=snapBenCounties.Name.map(splitAndGetSecondElement) \n",
    "\n",
    "#make a new column with the names:\n",
    "snapBenCounties = snapBenCounties.assign(StateName=pd.Series(states))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "snapBenCounties.head() # see to the rigth..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can count:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tableOut=pd.crosstab(snapBenCounties['StateName'],snapBenCounties['out2013'])\n",
    "\n",
    "tableOut.columns = ['normal', 'veryFewBeneficiaries','tooMuchBeneficiaries']\n",
    "tableOut.replace(0, np.nan,inplace=True) # sending 0 to missing\n",
    "tableOut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tells you an idea of the distributions of counties. For example, WA has one county whose number of beneficiaries are very high (compared to the rest of the country counties), Nebraska has the majority of counties that have very few beneficiaries.\n",
    "\n",
    "Let me get different __sets__ so I can make some queries later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# states with counties in the lower outliers\n",
    "lowOutStates=set(tableOut[\"veryFewBeneficiaries\"].dropna().index)\n",
    "# states with counties in the upper outliers\n",
    "upOutStates=set(tableOut[\"tooMuchBeneficiaries\"].dropna().index)\n",
    "# states with counties withinh 'normal' amount of beneficiaries\n",
    "normStates=set(tableOut[\"normal\"].dropna().index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we can start asking:\n",
    "\n",
    "* States with counties  in the upper outliers but that are not present in the lower ones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "upOutStates-lowOutStates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* States with counties  in the lower outliers but that are not present in the upper ones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lowOutStates-upOutStates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* States that have counties  in the upper and the lower outliers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lowOutStates & upOutStates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* States that have counties either in the upper or the lower outliers (not in both):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lowOutStates ^ upOutStates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* States that have no outlying counties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "normStates - (lowOutStates | upOutStates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Amount of states present in the data (uniting sets):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(normStates | upOutStates | lowOutStates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Notice that sets do not count duplicates, compare if we had lists and 'unite them' (the '|' symbol can not be applied to lists):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "len(list(normStates) + list(upOutStates) + list(lowOutStates))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "____\n",
    "\n",
    "\n",
    "### Footnotes\n",
    "<sup id=\"fn1\">1</sup>Take a look to this [blog post](https://inequality.org/research/unequal-americas-income-distribution/). <a href=\"#ref1\" >&#8593;</a>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "-----\n",
    "\n",
    "* [Go to page beginning](#head)\n",
    "* [Go to PART B: Bivariate EDA in Python](https://rawgit.com/EvansDataScience/govanalyticsweb/master/Python/P3B_BivariateEDA.html)\n",
    "* [Go to Course schedule](https://evansdatascience.github.io/GovernanceAnalytics/)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
